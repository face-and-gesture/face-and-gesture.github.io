---
layout: conference/participate
---

### Special Session- Application in Healthcare and Health Monitoring

#### Title

Applications in Healthcare and Health Monitoring

#### Description

Automated Human Health Monitoring Based on Computer Vision has gained rapid Automated Human Health Monitoring Based on Computer Vision has gained rapid scientific attention in the last decade, fueled by many research articles and commercial systems. Recently, the COVID-19 pandemic has pushed the need for virtual diagnosis and monitoring health protocols such as regulating social distancing, surveillance of individuals wearing masks in crowd, gauging body temperature and other physiological measurement from distance. Consequently, researchers from computer vision, as well as from the medical science community have given significant attention to goals ranging from patient analysis and monitoring to diagnostics (e.g., for dementia, depression, healthcare, physiological measurement, rare neurologic diseases). Moreover, healthcare represents an area of broad economic, social, and scientific impact. In addition, the recent pandemic scenario has claimed the need for health monitoring and surveillance of health protocols, which can be automated by various computer vision tools.
Hence, to elevate the state-of-the-art algorithms and to attract the attention of researchers, we organized related special sessions within the 14 th and 15 th IEEE International Conference on Automatic Face and Recognition (IEEE AFGR 2019 and 20). Due to the overwhelming success of the previous versions of the special session, we plan to host a successive session in conjunction with IEEE AFGR 2021. We aim to document recent advancements in automated healthcare, as well as to enable and discuss the progress. Therefore, the goal of this special session is to bring together researchers and practitioners working in this area of computer vision and medical science, and to address a wide range of theoretical and practical issues related to real-life healthcare systems. We especially invite papers resulting from collaboration between technical and clinical experts. Hence, this FG Special Session represents a venue for fostering these collaborations, providing a unique and welcoming environment for transdisciplinary research that is sometimes labeled as being “too clinical” by technical journals or “too technical” by clinical journals.

Topics of interest include, but are not limited to:

- Health monitoring based on face analysis,
- Health monitoring based on gesture analysis,
- Health monitoring using corporeal-based visual features,
- Depression analysis based on visual features,
- Face analytics for human behavior understanding,
- Anxiety diagnosis based on face and gesture,
- Physiological measurement employing face analytics,
- Databases on health monitoring, e.g., depression analysis,
- Augmentative and alternative communication,
- Human-robot interaction,
- Home healthcare,
- Technology for cognition,
- Automatic emotional hearing and understanding,
- Visual attention and visual saliency,
- Assistive living,
- Privacy preserving systems,
- Quality of life technologies,
- Mobile and wearable systems,
- Applications for the visually impaired,
- Sign language recognition and applications for hearing impaired,
- Applications for the ageing society,
- Personalized monitoring,
- Egocentric and first-person vision,
- Assessing physical and/or cognitive ability based on face and body movement analysis,
- Orofacial assessment in clinical populations,
- Hand function assessment in clinical populations,
- Assessment of gait and/or balance,
- Assistive technology,
- Applications to improve health and wellbeing of children and elderly.



#### Organizers

**Dr. Abhijit Das** is currently working as Assistant Professor at Thapar University, India. Previously, he has worked as visiting scientist at Indian Statistical Institute, researcher at the University of Southern California’s Viterbi School of Engineering Information Sciences Institute (USC/ISI).– Arlington Campus, Post-Doc Researcher at Inria Sophia Antipolis– Méditerranée, France and as a Research Administrator at the Faculty of Software Engineering & IT at University Technology of Sydney (UTS), Australia. Prior to his PhD, he has worked as an Associate Software Engineer at IBM India Pvt Ltd. and as a Lecturer at distinguished Universities. He has completed his PhD from the School of Information and Communication Technology, Griffith University, Australia. He is an accomplished machine learning and computer vision researcher with more than 10 years of research and teaching experience, presently pursuing investigation on learning representations and human analysis employing facial and corporeal-based visual features. During his research career, he has published several scientific articles in conferences, journals and a book chapter and has also received several awards from the IEEE, and other scientific organizations. Dr Das is involved in organizing scientific events such as international conferences, workshop, competitions and special sessions at conferences, and has served as guest editor for special issues, technical program committee member for several reputed international conferences and reviewer of top-ranking journals. He is also the winner of IBM research sponsored ECCV 2018 BEFA competition.

**Dr. Babak Taati** is a Scientist at KITE, the research arm of the Toronto Rehabilitation Institute - University Health Network. He is also an Assistant Professor in the Department of Computer Science, in the Institute of Biomedical Engineering (BME), and in the Rehabilitation Sciences Institute (RSI) at the University of Toronto (status only). His research applies computer vision and human body and facial movement tracking in the development and evaluation of intelligent health monitoring and rehabilitation technologies.

**Dr. Antitza Dantcheva** is a Researcher at the STARS team, INRIA, France. Previously, she was a Marie Curie fellow at INRIA and a Postdoctoral Fellow at the Michigan State University and the West Virginia University, USA. She received her PhD in Signal and Image Processing in 2011 from Eurecom / Telecom Paris Tech in France. In 2017, she has received the French National Research Agency (ANR) JCJC young researcher grant for her research project "Automated holistic human analysis". She was the recipient of the Best Presentation Award in ICME 2011, the Best Poster Award in ICB 2013, the Tabula Rasa Spoofing Award in 2013, as well as the Best Paper Award (Runner Up) at the IEEE ISBA 2017. Her research interests are in automated facial analysis for healthcare and security.

**Dr. Diego Guarin** is an Assistant professor in the Biomedical Engineering Program, Department of Biomedical and Chemical Engineering at the Florida Institute of Technology. His research focuses on the development of multimodal approaches for remote and intelligent assessment of neurological diseases based on video and audio recordings.

**Dr. Srijan Das** is a Postdoctoral Associate at Stony Brook University, USA. He completed his PhD in computer science at INRIA, Sophia Antipolis, France. His research interest involves analysis of spatio-temporal attention mechanisms for video understanding. He did his Post-Grad in computer science from the National Institute of Technology (NIT), Rourkela, India. He has published several research works in refereed journals and proceedings in the areas of computer vision and pattern recognition including ICCV, ECCV, WACV, etc. He is serving the community by organizing scientific events and has volunteered at ICACNI 2014, ICACNI 2016, ICCV 2019, ICLR 2020 & ICML 2020.He has also mentored for the Emerging Technology Business Incubator (ETBI) led by NIT Rourkela, a platform envisaged to transform the start-up ecosystem of the region. He is reviewer for several international journals (PR, CVIU, FGCS, Comput. Electr. Eng., MTAP, and Signal Process. Image Commun.) and conferences (ICACIE, SETIT, KCST, ICAML, AVSS, WACV, CVPR, ICCV, IROS).

**Dr. Andrea Bandini** is currently a postdoctoral research fellow at KITE – Toronto Rehab – UHN. He got a Ph.D. (2016) in Bioengineering from the University of Bologna (Italy). The goal of his research is to improve access to healthcare and optimize interventions in people with neurological disorders by developing multi-modal and intelligent tools for remote clinical assessment. His research focuses on neurological disorders and ageing and lies at the intersection of artificial intelligence, computer vision, biomedical signal processing, and rehabilitation engineering.

**Prof. Hu Han** is Associate Professor of the Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS). He received the B.S. degree from Shandong University, and the Ph.D. degree from ICT, CAS, in 2005 and 2011, respectively, both in computer science. Prior to joining ICT, CAS as associate professor, he was a Research Associate in the PRIP Lab at the Michigan State University, and a visiting researcher at Google in Mountain View from 2011 to 2015. His research interests include computer vision, pattern recognition, and biometrics. He has published more than 70 papers in journals and conferences including IEEE Trans. PAMI, IEEE Trans. IP, IEEE Trans. IFS, IEEE Trans. BIOM, IEEE Trans. MI, IEEE Trans. CSVT, Pattern Recognition, CVPR, NeurIPS, ECCV, MICCAI, with more than 3600 Google Scholar citations. He was a recipient of the 2020 IEEE Signal Processing Society Best Paper Award, 2019 IEEE FG Best Poster Presentation Award, and 2016/2018 CCBR Best Student/Poster Award. He is/was an organizer of a number of special sessions and workshops in ICCV2021 / CVPR2020 / FG2020 / WACV2020 / FG2019. He is/was the Associate Editor of Pattern Recognition, VALSE LAC, ICPR2020 Area Chair, and IJCAI2021 SPC.

**Dr. Yana Yunusova** is currently a Professor in the Department of Speech Language Pathology (SLP) and an Acting Director in the Rehabilitation Sciences Institute (RSI) at the University of Toronto. She is an Associate Scientist at Sunnybrook Research Institute and a Senior Scientist at UHN Toronto Rehabilitation Institute. Her research is also focused on the development of technologies for automatic assessment of speech and novel methods of speech therapy that aim to impact clinical practice in the fields of speech language pathology and neurology.

**Dr. François Brémond** is Research Director and head of the STARS team at INRIA Sophia Antipolis. He has conducted research in video understanding since 1993 both at Sophia-Antipolis and at USC (University of Southern California), LA. In 1997 he obtained his PhD degree from INRIA in video understanding. He is co-founder of CoBTek, a team comprising the Nice Hospital in France, with the goal to study behavioral disorders for older adults suffering from dementia. He designs and develops generic systems for dynamic scene interpretation. The targeted class of applications is the automatic interpretation of indoor and outdoor scenes observed by sensors and in particular by monocular color cameras. These systems detect and track mobile objects, which can be either humans or vehicles, and recognize their behaviors. He is particularly interested in filling the gap between sensor information (pixel level) and behavior recognition (semantic level). François Brémond is author or co-author of more than 200 scientific papers published in international journals or conferences in video understanding. He is reviewer for several international journals (CVIU, IJPRAI, IJHCS, PAMI, AIJ, Eurasip JASP, etc) and conferences (CVPR, ICCV, AVSS, VS, ICVS, etc).

**Prof. Xilin Chen** is a professor with the Institute of Computing Technology, Chinese Academy of Sciences (CAS). He has authored one book and more than 200 papers in refereed journals and proceedings in the areas of computer vision, pattern recognition, image processing, and multimodal interfaces. He was a recipient of several awards, including the China’s State Natural Science Award in 2015, the China’s State S&T Progress Award in 2000, 2003, 2005, and 2012 for his research work. He is currently a senior associate editor of the Journal of Visual Communication and Image Representation, and an associate editor-in-chief of the Chinese Journal of Computers, and Chinese Journal of Pattern Recognition and Artificial Intelligence. He served as an Organizing Committee member for many conferences, including general co-chair of FG13 / FG18, and an area chair of CVPR 2017 / 2019 / 2020, and ICCV 2019. He is a fellow of the ACM, IEEE, IAPR, and CCF.

------

### Special Session on EmoCrowdSSFG 2021



#### Title

EMOCROWD: group-level emotions and crowd analysis for recognition of anomalous actions, events, and sentiments

#### Description

Crowd analysis has become an important area in computer vision, due to the breadth of applications that rely on crowd density, movement, and management. Techniques for crowd /group analysis are of interest in video-surveillance, where it is necessary to detect anomalous events due to individual or social behaviours. For example, detecting violent events such as “bullying”, is individually and socially relevant for their impact on the victims. Beyond bullying or violent events, one could also consider that specific crowd events and actions may be detected from group-level emotions, and provide important contextual information on the surroundings of a group for situation awareness (for example, an entertaining show on TV).

This special session aims to collect a number of contributions that allow stating the main novelties around the topic. With the advent of Deep Learning models, several innovative techniques wererecently proposed, yet several key challenges remain. Therefore, this special session is devoted to recent advances in crowd analysis approaches and related technologies. In particular, we invite papers describing new machine learning and computer vision models for actions, events, and group-level emotions that rely on the recognition of facial expressions, body movement and gestures, and the analysis of crowd densities and movement.

We want to make this special session the first opportunityof viewpoints’ exchange and methods’ sharingto answer the “where are we?” question on the crucial challenges above,thanks to the contribution of leading experts in computer vision, pattern recognition, and artificial intelligence.

Suggested topics include the following areas as they apply to crowd analysis, but are not limited to:

- Analysis of Crowd Densities and Movements
- Action and Event Recognition
- Video Group-Level Emotion Recognition
- Anomaly Detection
- Unsupervised crowd/group analysis
- Spatiotemporal Recognition of Facial and Vocal Expressions
- Attention Mechanisms
- Self-Supervised Techniques for Crowd/Group Analysis
- New Databases
- Applications

#### Organizers

**Gian Luca Marcialis**, PhD, IEEE Senior Member, is currently associate professor at the University of Cagliari (Italy), with the Pattern Recognition and Applications Laboratory ([PRA Lab](http://pralab.diee.unica.it/)). Team leader of the PRA Lab's Biometric Unit, his scientific contributions include more than one hundred papers on fingerprint presentation attack detection, biometric template update by semi-supervised approaches, fusion of multiple biometric matchers for person recognition and crowd analysis. He founded theInternational Fingerprint Liveness Detection Competition ([LivDet](https://livdet.diee.unica.it/)), aimed at benchmarking fingerprint presentation attack detection algorithms. This event is now the first international meeting of public and private organizations for assessing the state of the art on facing with the threat above. Dr. Marcialis is also one of the [BullyBuster project’s leaders](http://www.bullybuster.unina.it/). The project is aimed at the prevention and repression of bullying and cyberbullying attitudes through behavioural biometrics, crowd analysis and machine learning algorithms. For further information, please visit the [Prof. Marcialis’ web page](https://www.unica.it/unica/en/ateneo_s07_ss01_sss01.page?contentId=SHD30551).

**Eric Granger**, Ph.D., is the FRSQ Research Co-Chair in AI in Digital Health and Life Sciences, and the ETS Industrial Research Chair on Embedded Neural Networks for Intelligent Connected Buildings. He is also Professor in the Dept. of Systems Engineering at École de technologie supérieure ([ETS](https://www.etsmtl.ca/)), and Director of the Laboratoire d’imagerie, de vision et d’intelligence artificielle ([LIVIA](http://liviamtl.ca/)). His research expertise includes machine learning, pattern recognition, and computer vision, with applications in affective computing, biometrics, face recognition, medical image analysis, and video analytics/surveillance. His contributions on the development of DL models for video-based face recognition has led to several collaborations with governmental and industrial partnerslike CBSA, Nuvoola, Ericsson, and Genetec Inc. To date, Dr. Granger has authored over 180 peer-reviewed papers and supervised /co-supervised 50+ postdocs and graduate students. He is an associate editor for Elsevier Pattern Recognition, Springer Nature Computer Science, and the EURASIP Journal on Image and Video Processing.

**Abhinav Dhall**, Ph.D., is a Senior Lecturer at Monash University, where he co-directs the Human-Centred Artificial Intelligence lab. He also holds an Assistant Professor position at the Indian Institute of Technology Ropar. He is co-chair for Doctoral Consortium & Challenges at IEEE FG 2021. He also received Reviewer award at IEEE FG 2018, Best Honorable Paper Award at FG 2013 and Best Doctoral Consortium Paper Award at ACM ICMR 2013.

**Giulia Orrù**, Ph.D., is currently postdoc at the University of Cagliari, Pattern Recognition and Applications Laboratory (PRA Lab). Since 2014 she collaborates with the PRA Lab's Biometric Unit working in face recognition, fingerprint liveness detection, adaptive biometric systems and crowd analysis. She is member of the BullyBuster project, aimed at the prevention and repression of bullying and cyberbullying attitudes through behavioural biometrics and crowd analysis.


------

### Call for Special Sessions Proposals



We invite special sessions proposals for the 2021 IEEE Conference on Automatic Face and Gesture Recognition (FG 2021:http://iab-rubric.org/fg2021/). Accepted special sessions will be organized as part of the main conference.

For Special Sessions, we particularly encourage proposals that highlight emerging new fields, application domains and challenges related to face and gesture as well as interdisciplinary topics that bring new perspectives to the FG community. These Special Sessions will emphasize “Frontiers in FG” in the face and gesture recognition research field. It is possible to propose panels in this category. Proposers should have a strong record in the proposed field.

The special session paper submission with be handled as part of the second round of submissions to the FG2021, see http://iab-rubric.org/fg2021/important_dates.html. For accepted special session, proposers will act as area chairs and supervise the reviewing process of the papers marked for the special session in the second round of submissions.The deadline for all workshop proposals is May 10, 2021. Decisions will be announced by May 24, 2021.

#### Important Dates

Special Session proposals due: May 10, 2021
Special Session proposal notification: May 24, 2021
Special Session papers due: second round paper submission deadline, currently August 1, 2021

#### Special Session Proposal Submission

Special session proposals must be sent in PDF format to the FG 2021 Workshop and SpecialSession Co-chairs, Zakia Hammal ([zakia_hammal@yahoo.fr](mailto:zakia_hammal@yahoo.fr)) and Jonathon Phillips ([jonathon.phillips@nist.gov](mailto:jonathon.phillips@nist.gov)) with email subject “FG 2021 Special Session Proposal: [title of your special session]”. A proposal should include the following information to facilitate the decision process:

- The title of the proposed Special Session or Panel.
- A brief description of the topic, including how it stands apart from the regular FG topics/sessions.
- Contact information and short bio of the organizers.
- For a Special Session: a list of proposed contributions to the special session (including authors, title, and short abstract).
- For a Panel: a list of proposed panelists and their expected perspectives/contributions. Paper preparation and review details.



Special Session papers will be part of the conference proceedings and will be reviewed along with the regular conference submissions. Papers submitted to a Special Session should describe original work and should follow the general FG submission guidelines.

For your reference, below is a list of special sessions held in conjunction with FG 2020:

- [Challenges In Modeling And Representation Of Gestures In Human Interactions](https://fg2020.org/challenges-in-modeling-and-representation-of-gestures-in-human-interactions/)
- [Advances And Challenges In Face And Gesture Based Security Systems (Acfgss 2020)](https://fg2020.org/advances-and-challenges-in-face-and-gesture-based-security-systems-acfgss-2020/)
- [Computer Vision For Automatic Human Health Monitoring](https://fg2020.org/computer-vision-for-automatic-human-health-monitoring/)
- [Face And Body Movement Analysis – Applications In Healthcare](https://fg2020.org/face-and-body-movement-analysis-applications-in-healthcare/)